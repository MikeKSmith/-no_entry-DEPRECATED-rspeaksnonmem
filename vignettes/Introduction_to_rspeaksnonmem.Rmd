---
title: "Introduction to rspeaksnonmem"
author: "Mike K Smith (Mike.K.Smith@Pfizer.com)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=6)
```

## What does `rspeaksnonmem` do?

`rspeaksnonmem` is designed to allow the user to craft workflows based on a given NONMEM model. It is not intended to replace Perl speaks Nonmem (PsN) - in fact `rspeaksnonmem` can call and use PsN functionality from an R script. In fact `rspeaksnonmem` could equally be called "rspeaksPsN". `rspeaksnonmem` helps the user by allow them to write complex workflows using NONMEM, PsN and R. For example performing data checkout (exploratory analysis), using a "template" model as a starting point for model refinement, specifying and running a sequence of tasks for every model, collating results across models for model comparison.

After importing and parsing a control stream to an R object using the `RNMImport` package, `rspeaksnonmem` allows the user to easily change initial estimates, change data attributes or change task properties (estimation or simulation settings) without having to change the model. This saves a lot of textual searching by the user. 

To best use `rspeaksnonmem` it is useful to think of the NMTRAN expression of the model as a combination of:
* Data specification
* Parameter specification
* Model specification (structural, covariate and stochastic components)
* Task specification
 
With `rspeaksnonmem` it is easy to alter data, parameter and task information, but altering the model specification has knock-on effects across many other aspects. We recommend that the user sets up the model in such a way that it is easy to change the model simply by fixing or estimating certain parameters i.e. fixing population parameters and/or altering the OMEGA and SIGMA parameter specification. 

Using a template model and a user-specified workflow function e.g. a function combining `execute_PsN` + `sumo_PsN` + `basic_GOF` the user could specify a number of combinations of THETA, OMEGA and SIGMA that would test a range of plausible models, run these models and then compare the output (OFV / AIC and model diagnostics) to find the best model fit. This is suggested not as a way of finding the best ***final*** model, but the best ***base*** model for further refinement. There is no substitute for the knowledge and skill of an analyst in building and assessing models. We refer the reader to Schmidt and Radivojevic (2014), JPKPD (<http://www.ncbi.nlm.nih.gov/pubmed/25056507>).

## Installation 

### Dependencies 

`rspeaksnonmem` relies on the package [`RNMImport`](https://github.com/MangoTheCat/RNMImport) function 
`importNmMod` which reads and parses the NONMEM control stream. `rspeaksnonmem` then works with
the data, parameter values, and task information separately from the model.

Before installation of `rspeaksnonmem`, the package `RNMImport` needs to be installed.
Install RNMIMport from Github using the `devtools` package:

```{r install_RNMImport, include=F}
  #devtools::install_git("MangoTheCat/RNMImport")
```

### Install rspeaksnonmem
Eventually, `rspeaksnonmem` will be released to CRAN, but while still in development `rspeaksnonmem` can most easily be installed from GitHub using the `devtools` package:

```{r install_rspeaksnonmem, include=F}
    #devtools::install_github("MikeKSmith/rspeaksnonmem")
```

Alternatively, if the source files are available locally, you can load the functions
directly.
```{r,echo=FALSE,results='hide',message=FALSE}
 devtools::load_all(pkg = ".")
 devtools::load_all(pkg = "C:\\Users\\smith_mk\\Documents\\Working documents\\RNMImport")
```

Load the `rspeaksnonmem` package
```{r, include=FALSE, echo=FALSE}
#library(rspeaksnonmem)
```

Copy an example dataset and model to a directory of your choice

```{r,results='hide',echo=T}
getwd()

file.copy(from = file.path(system.file("exdata", package = "rspeaksnonmem"),
                           "warfarin_conc_pca.csv"),
            to = getwd(), overwrite = T )
file.copy(from = file.path(system.file("exdata", package = "rspeaksnonmem"),
                           "warfarin_bootstrap50.dta"),
            to = getwd(), overwrite = T )
file.copy(from = file.path(system.file("exdata", package = "rspeaksnonmem"),
                           "warfarin.ctl"),
            to = getwd(), overwrite = T )
```

The initial model within the workflow should act as a "template" for modifications. The best practice is to use a model where all possible parameters are defined (including OMEGAs and covariances / correlations) but where it is possible to fix parameters to zero or some null value. We can then run and test a wide variety of models simply by updating the $THETA, $OMEGA and $SIGMA parameters to allow estimation.

## Read the control stream using RNMImport 
First, we need to read the NONMEM control stream into R using the importNmMod function of RNMImport.
```{r readControlStream}
warfModel <- importNmMod("warfarin.ctl")
class(warfModel)
names(warfModel)
```

We can select the parsed control stream as the basis for modification:
```{r viewParsedNM}
warfTemplateModel <- warfModel$problemContents[[1]]
```

We can change the dataset. Here I've sampled 50 subjects from the original warfarin dataset (warfarin.csv) into a dataset called "warfarin_bootstrap50.dta".

```{r updateDataset}
newData <- warfModel$problemContents[[1]]$Data
newData[,"File"] <- "warfarin_bootstrap50.dta"
```

Using `rspeaksnonmem` the user can then update elements of the model using this parsed set of commands. `rspeaksnonmem` provides some additional functions to extract certain elements of the parsed control stream. We view the $DATA and $INPUT commands as "Data" items; $THETA, $OMEGA and $SIGMA as "Parameter" items; $EST, $COV and $TAB as "Task" items; and everything else as "Model" items. 

Similarly, `getNMParameterObjects` returns the $THETA, $OMEGA and $SIGMA records.
```{r getNMParameterObjects}
params <- getNMParameterObjects(warfModel)
params
```

Together the Data, Parameters, Model and Task information forms a "Modelling Object Group" or MOG which is used for a specific estimation task.

The template model has POP_TLAG fixed to zero. To "unfix" this, we need to provide lower, initial (Est) and upper bounds for POP_TLAG. Note that params$Theta has named rows using the comments after each THETA line in the NMTRAN control stream.
```{r specifyTHETAs}
FIX_POP_TLAG <- list(Lower = 0, Est = 0, Upper = 0, FIX = TRUE, comments = "POP_TLAG")
EST_POP_TLAG <- list(Lower = 0, Est = 0.75, Upper = 1.5, FIX = FALSE, comments = "POP_TLAG")

thetaNoLag <- warfTemplateModel$Theta
thetaNoLag["POP_TLAG",] <- FIX_POP_TLAG

thetaLag <- warfTemplateModel$Theta
thetaLag["POP_TLAG",] <- EST_POP_TLAG
```

The template model has proportional error only. RUV is set up as THETA * SIGMA where SIGMA ~ N(0,1).
```{r specifyRUV}
ruvAdd <- list(Lower = 0, Est = 0.1, FIX = FALSE, comments = "RUV_ADD")
thetaLagComboRUV <- thetaLag
thetaLagComboRUV["RUV_ADD",] <- ruvAdd
```

The template model specifies an OMEGA block (covariance) between ETA_CL and ETA_V.
```{r specifyOMEGAs}
fullBlockOmega <- list(values = MSToolkit::parseCovMatrix(
  c(0.1, 
    0.01, 0.1, 
    0.01, 0.01, 0.1, 
    0.01, 0.01, 0.01, 0.1), nCov = 4),
                       block = 4, FIX = FALSE)
CLVKABlock <- list(list(values = MSToolkit::parseCovMatrix(
  c(0.1, 
    0.01, 0.1, 
    0.01, 0.01, 0.1), nCov = 3),
                       block = 3, FIX = FALSE),
                   list(values = 0.1, FIX = FALSE))
CLVBlock_noTLAG <- params$OMEGA
diagPPV <- list(values = diag(c(0.1,0.1,0.1,0.1)), FIX = FALSE)
diagPPV_noTLAG <- list(list(values = diag(c(0.1,0.1,0.1)), FIX = FALSE),
                            list(values = 0, FIX = TRUE))
diagCLV_noKATLAG <- list(data.frame(values = c(0.1, 0.1, 0, 0), 
                                    FIX = c(rep(FALSE,2), rep(TRUE,2)),
                               comments = c("PPV_CL","PPV_V","PPV_KA","PPV_TLAG")))
```

We can now combine these to test a number of possible models:
```{r defineModels}
  run1 <- updateModel(warfTemplateModel, 
                      theta = thetaNoLag, 
                      omega = diagCLV_noKATLAG, 
                      data = newData, 
                      runno = 1) ## First model

  run2 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = diagCLV_noKATLAG, 
                      data = newData,   
                      runno = 2)  ## Add POP_TLAG
  
  run3 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = diagPPV_noTLAG, 
                      data = newData,     
                      runno = 3)  ## Add PPV_KA
  
  run4 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = CLVBlock_noTLAG, 
                      data = newData,    
                      runno = 4)  ## Change to block CL, V
  
  run5 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = diagPPV, 
                      data = newData,            
                      runno = 5)  ## Add PPV_TLAG
  
  run6 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = CLVKABlock, 
                      data = newData,         
                      runno = 6)  ## Change to block CL, V, KA
  
  run6 <- updateModel(warfTemplateModel, 
                      theta = thetaLag, 
                      omega = fullBlockOmega, 
                      data = newData,     
                      runno = 7)  ## full block OMEGA
  
  run7 <- updateModel(warfTemplateModel, 
                      theta = thetaLagComboRUV, 
                      omega = fullBlockOmega, 
                      data = newData, 
                      runno = 8)  ## Combined RUV model (add + prop) 
```

We can define the the sequence of steps (workflow) we want to take with each model:
```{r defineWorkflow}
myPopPKWorkflow <- function(model, controlFile, lstFile, dataFile, workingDir=NULL){
  if ( is.null(workingDir) ) workingDir <- file.path(getwd(),deparse(substitute(model)))
  dir.create(workingDir)

  file.copy(from = model$Data[,"File"], to = workingDir)
  
  origWD <- getwd()
  setwd(workingDir)
    
  controlFile <- paste(deparse(substitute(model)),".ctl",sep = "")
  lstFile <- paste(deparse(substitute(model)),".lst",sep = "")
 
  writeNMControlStream(templateModel = warfModel$Raw, parsedControl = list(model),
                       outputFile = controlFile)

  estimate_NM(modelFile = controlFile, lstFile = lstFile, 
              command = "nonmem-7.2", cleanup = T)
              
  sumo_PsN(command = "sumo-3.5.4", listFile = lstFile)

  runno <- as.numeric(gsub("[a-z]", "", list.files(pattern = "^sdtab")[1]))
  
  ## ----createXpdb----------------------------------------------------------
  xpdb <- xpose4::xpose.data(runno, quiet = T)
  # save(base.xpdb, file='Xpose database.RData')
  
  ## ----xposeGOF------------------------------------------------------------
  print(xpose4::dv.vs.pred.ipred(xpdb))
  print(xpose4::pred.vs.idv(xpdb))
  print(xpose4::ipred.vs.idv(xpdb))
  print(xpose4::wres.vs.idv(xpdb))
  print(xpose4::wres.vs.pred(xpdb))
  print(xpose4::ranpar.hist(xpdb))
  print(xpose4::ind.plots(xpdb, layout = c(4, 4)))  

  on.exit(setwd(origWD))
}
```

We can then run the workflow for each model in turn and compare the results, using the output list as the basis for reporting.

```{r runModel1}
 Model1 <- myPopPKWorkflow(run1)
```

